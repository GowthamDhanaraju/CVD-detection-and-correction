version: '3.8'

services:
  # Backend API Service (Production)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: cvd-backend-prod
    ports:
      - "8001:8000"
    environment:
      - HOST=0.0.0.0
      - PORT=8000
      - LOG_LEVEL=WARNING
      - REDIS_URL=redis://redis:6379
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - SECRET_KEY=${SECRET_KEY:-your-production-secret-key}
      - ACCESS_TOKEN_EXPIRE_MINUTES=60
    volumes:
      - ./backend/data:/app/data:ro
      - ./backend/models:/app/models:ro
      - backend_uploads:/app/uploads
    depends_on:
      - redis
      - kafka
    networks:
      - cvd-network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Frontend Web Service (Production)
  frontend:
    build:
      context: ./mobile-app
      dockerfile: Dockerfile
    container_name: cvd-frontend-prod
    ports:
      - "8082:8080"
    environment:
      - NODE_ENV=production
      - REACT_APP_API_URL=http://localhost:8001
    depends_on:
      - backend
    networks:
      - cvd-network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Redis Service (Production)
  redis:
    image: redis:7-alpine
    container_name: cvd-redis-prod
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - cvd-network
    restart: always
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Kafka Services (Production)
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: cvd-zookeeper-prod
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_HEAP_OPTS: "-Xmx512m -Xms512m"
    networks:
      - cvd-network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: cvd-kafka-prod
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - cvd-network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G

  # Nginx Reverse Proxy (Production)
  nginx:
    image: nginx:alpine
    container_name: cvd-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
      - frontend
    networks:
      - cvd-network
    restart: always

networks:
  cvd-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  redis_data:
    driver: local
  kafka_data:
    driver: local
  backend_uploads:
    driver: local